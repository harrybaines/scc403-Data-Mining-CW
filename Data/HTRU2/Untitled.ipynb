{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2792, 0.0132, 0.1748],\n",
      "        [0.4179, 0.4092, 0.5358],\n",
      "        [0.0369, 0.4737, 0.9927],\n",
      "        [0.0596, 0.7427, 0.0075],\n",
      "        [0.9482, 0.9785, 0.4293]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    data_raw = []\n",
    "    labels_raw = []\n",
    "    \n",
    "    with open(filepath) as file:\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "\n",
    "            line = line.rstrip()\n",
    "            read_data = line.split(',')\n",
    "            for pos in range(len(read_data) - 1):\n",
    "                read_data[pos] = float(read_data[pos])\n",
    "\n",
    "            data_raw.append(read_data[0:4])\n",
    "\n",
    "            if (read_data[4] == 'Iris-setosa'):\n",
    "                labels_raw.append(0)\n",
    "            if (read_data[4] == 'Iris-versicolor'):\n",
    "                labels_raw.append(1)\n",
    "            if (read_data[4] == 'Iris-virginica'):\n",
    "                labels_raw.append(2)\n",
    "\n",
    "            data = np.array(data_raw)\n",
    "            labels = np.array(labels_raw)\n",
    "            return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(data):\n",
    "    normalised_data = data.copy()\n",
    "    rows, cols = data.shape\n",
    "    \n",
    "    for j in range(cols):\n",
    "        max_element = np.amax(data[:, j])\n",
    "        min_element = np.amin(data[:, j])\n",
    "        \n",
    "        for i in range(rows):\n",
    "            normalised_data[i, j] = (data[i, j] - min_element) / (max_element - min_element)\n",
    "\n",
    "    return normalised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
